import streamlit as st
import numpy as np
from PIL import Image
import cv2
import onnxruntime as ort
import os

st.set_page_config(page_title="ç”µç¼†ç¼ºé™·æ£€æµ‹ç³»ç»Ÿ", layout="wide")
st.title("ğŸ”Œ ç”µç¼†ç¼ºé™·æ£€æµ‹ç³»ç»Ÿ")
st.markdown("ä¸Šä¼ ç”µç¼†å›¾ç‰‡ï¼ŒAIè‡ªåŠ¨æ£€æµ‹å„ç§ç¼ºé™·ç±»å‹")

@st.cache_resource
def load_onnx_model():
    """åŠ è½½ONNXæ¨¡å‹"""
    try:
        # æŸ¥æ‰¾å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶
        onnx_files = [f for f in os.listdir('.') if f.endswith('.onnx')]
        st.info(f"æ‰¾åˆ°çš„ONNXæ–‡ä»¶: {onnx_files}")
        
        if not onnx_files:
            st.error("âŒ æœªæ‰¾åˆ°ONNXæ¨¡å‹æ–‡ä»¶")
            return None
        
        model_path = onnx_files[0]
        st.info(f"å°è¯•åŠ è½½æ¨¡å‹: {model_path}")
        
        # è®¾ç½®ONNX Runtimeæä¾›è€…
        providers = ['CPUExecutionProvider']
        if ort.get_device() == 'GPU':
            providers.insert(0, 'CUDAExecutionProvider')
        
        session = ort.InferenceSession(model_path, providers=providers)
        
        # æ˜¾ç¤ºæ¨¡å‹è¾“å…¥ä¿¡æ¯
        model_inputs = session.get_inputs()
        st.success(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        for i, input_info in enumerate(model_inputs):
            st.info(f"è¾“å…¥ {i}: åç§°='{input_info.name}', å½¢çŠ¶={input_info.shape}, ç±»å‹={input_info.type}")
        
        return session
        
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None

def preprocess(image, input_size=640):
    """é¢„å¤„ç†å›¾åƒ - ä¿®å¤ç»´åº¦é—®é¢˜"""
    # ç¡®ä¿å›¾åƒæ˜¯3é€šé“
    if len(image.shape) == 3 and image.shape[2] == 4:
        # å¦‚æœæ˜¯4é€šé“RGBAï¼Œè½¬æ¢ä¸º3é€šé“RGB
        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
    elif len(image.shape) == 2:
        # å¦‚æœæ˜¯ç°åº¦å›¾ï¼Œè½¬æ¢ä¸º3é€šé“
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    
    # è°ƒæ•´å°ºå¯¸
    img = cv2.resize(image, (input_size, input_size))
    
    # å½’ä¸€åŒ–
    img = img.astype(np.float32) / 255.0
    
    # è½¬æ¢é€šé“é¡ºåº: HWC to CHW
    img = img.transpose(2, 0, 1)  # ä» [H, W, C] åˆ° [C, H, W]
    
    # æ·»åŠ æ‰¹æ¬¡ç»´åº¦: [C, H, W] åˆ° [1, C, H, W]
    img = np.expand_dims(img, 0)
    
    return img

def yolo_postprocess(outputs, original_shape, input_size=640, conf_threshold=0.25):
    """YOLOv8 ONNXè¾“å‡ºåå¤„ç† - ä¿®å¤ç‰ˆæœ¬"""
    try:
        # YOLOv8 ONNXè¾“å‡ºæ ¼å¼é€šå¸¸æ˜¯ [1, 84, 8400]
        predictions = outputs[0]  # shape: [1, 84, 8400]
        
        boxes = []
        scores = []
        class_ids = []
        
        # è®¡ç®—ç±»åˆ«æ•°: 84 = 4(bbox) + 80(classes) æˆ– 13 = 4 + 1 + 8
        num_features = predictions.shape[1]
        if num_features == 84:  # COCO 80ç±»
            num_classes = 80
            has_obj_conf = False
        elif num_features == 13:  # è‡ªå®šä¹‰8ç±» + obj_conf
            num_classes = 8
            has_obj_conf = True
        else:
            # è‡ªåŠ¨æ¨æ–­
            num_classes = num_features - 5  # å‡è®¾æœ‰obj_conf
            has_obj_conf = True
        
        st.info(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {predictions.shape}, ç±»åˆ«æ•°: {num_classes}")
        
        # éå†æ‰€æœ‰8400ä¸ªé¢„æµ‹
        for i in range(predictions.shape[2]):
            prediction = predictions[0, :, i]
            
            if has_obj_conf:
                # æ ¼å¼: [x_center, y_center, width, height, obj_conf, class_probs...]
                x_center, y_center, width, height, obj_conf = prediction[0:5]
                class_probs = prediction[5:5+num_classes]
            else:
                # æ ¼å¼: [x_center, y_center, width, height, class_probs...]
                x_center, y_center, width, height = prediction[0:4]
                class_probs = prediction[4:4+num_classes]
                obj_conf = 1.0  # å¦‚æœæ²¡æœ‰obj_confï¼Œè®¾ä¸º1.0
            
            # è½¬æ¢ä¸ºåƒç´ åæ ‡
            x1 = (x_center - width / 2) * input_size
            y1 = (y_center - height / 2) * input_size
            x2 = (x_center + width / 2) * input_size
            y2 = (y_center + height / 2) * input_size
            
            # è·å–ç±»åˆ«
            class_id = np.argmax(class_probs)
            class_conf = class_probs[class_id]
            
            # ç»¼åˆç½®ä¿¡åº¦
            confidence = obj_conf * class_conf
            
            if confidence > conf_threshold:
                # ç¼©æ”¾å›åŸå›¾å°ºå¯¸
                scale_x = original_shape[1] / input_size
                scale_y = original_shape[0] / input_size
                
                x1 = int(x1 * scale_x)
                y1 = int(y1 * scale_y)
                x2 = int(x2 * scale_x)
                y2 = int(y2 * scale_y)
                
                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, min(x1, original_shape[1]))
                y1 = max(0, min(y1, original_shape[0]))
                x2 = max(0, min(x2, original_shape[1]))
                y2 = max(0, min(y2, original_shape[0]))
                
                # åªæ·»åŠ æœ‰æ•ˆçš„è¾¹ç•Œæ¡†
                if x2 > x1 and y2 > y1:
                    boxes.append([x1, y1, x2, y2])
                    scores.append(float(confidence))
                    class_ids.append(int(class_id))
        
        return boxes, scores, class_ids
        
    except Exception as e:
        st.error(f"åå¤„ç†é”™è¯¯: {e}")
        return [], [], []

# ç±»åˆ«åç§°æ˜ å°„
CLASS_NAMES = {
    0: "æ–­è£‚è‚¡çº¿", 1: "ç„Šæ¥è‚¡çº¿", 2: "å¼¯æ›²è‚¡çº¿", 3: "é•¿åˆ’ç—•",
    4: "å‹ç¢", 5: "é—´éš”è‚¡çº¿", 6: "æ²‰ç§¯ç‰©", 7: "æ–­è£‚",
    8: "é›·å‡»æŸå"
}

def draw_detections(image, boxes, scores, class_ids, conf_threshold=0.25):
    """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    result = image.copy()
    
    # é¢œè‰²æ˜ å°„
    colors = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
        (255, 0, 255), (0, 255, 255), (255, 165, 0), (128, 0, 128),
        (165, 42, 42)
    ]
    
    for i, (box, score, class_id) in enumerate(zip(boxes, scores, class_ids)):
        if score > conf_threshold:
            x1, y1, x2, y2 = box
            
            # é€‰æ‹©é¢œè‰²
            color = colors[class_id % len(colors)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(result, (x1, y1), (x2, y2), color, 3)
            
            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
            class_name = CLASS_NAMES.get(class_id, f"ç±»åˆ«{class_id}")
            label = f"{class_name} {score:.2f}"
            
            # è®¡ç®—æ ‡ç­¾å°ºå¯¸
            (label_width, label_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
            )
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            label_bg_y1 = max(0, y1 - label_height - 10)
            label_bg_y2 = y1
            cv2.rectangle(result, 
                         (x1, label_bg_y1),
                         (x1 + label_width, label_bg_y2),
                         color, -1)
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
            cv2.putText(result, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    return result

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ æ£€æµ‹è®¾ç½®")
    confidence_threshold = st.slider(
        "ç½®ä¿¡åº¦é˜ˆå€¼", 
        min_value=0.1, 
        max_value=0.9, 
        value=0.25,
        help="å€¼è¶Šå°æ£€æµ‹è¶Šæ•æ„Ÿï¼Œä½†å¯èƒ½äº§ç”Ÿæ›´å¤šè¯¯æ£€"
    )
    
    st.markdown("---")
    st.markdown("### æ”¯æŒæ£€æµ‹çš„ç¼ºé™·ç±»å‹")
    for class_id, class_name in CLASS_NAMES.items():
        st.write(f"â€¢ {class_name}")

# ä¸»ç•Œé¢
st.markdown("---")

# åŠ è½½æ¨¡å‹
model_session = load_onnx_model()

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader(
    "ğŸ“¤ ä¸Šä¼ ç”µç¼†å›¾ç‰‡", 
    type=['jpg', 'jpeg', 'png'],
    help="æ”¯æŒ JPGã€JPEGã€PNG æ ¼å¼"
)

if uploaded_file is not None:
    # è¯»å–å¹¶æ˜¾ç¤ºåŸå›¾
    image = Image.open(uploaded_file)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„æ—¶ç¡®ä¿å¤„ç†RGBAå›¾åƒ
    if image.mode == 'RGBA':
        image = image.convert('RGB')
    
    image_np = np.array(image)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“· åŸå›¾")
        st.image(image, use_column_width=True)
    
    # æ£€æµ‹æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹æ£€æµ‹", type="primary", use_container_width=True):
        if model_session is None:
            st.error("âŒ æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œæ£€æµ‹")
        else:
            with st.spinner("ğŸ” AIæ­£åœ¨æ£€æµ‹ç”µç¼†ç¼ºé™·..."):
                try:
                    # è·å–æ¨¡å‹è¾“å…¥ä¿¡æ¯
                    input_name = model_session.get_inputs()[0].name
                    input_shape = model_session.get_inputs()[0].shape
                    st.info(f"æ¨¡å‹æœŸæœ›è¾“å…¥: {input_name}, å½¢çŠ¶: {input_shape}")
                    
                    # é¢„å¤„ç†
                    input_data = preprocess(image_np)
                    st.info(f"é¢„å¤„ç†åå½¢çŠ¶: {input_data.shape}")
                    
                    # éªŒè¯è¾“å…¥å½¢çŠ¶
                    expected_shape = tuple(input_shape)
                    actual_shape = input_data.shape
                    
                    if actual_shape != expected_shape:
                        st.warning(f"è¾“å…¥å½¢çŠ¶ä¸åŒ¹é…: å®é™…{actual_shape} vs æœŸæœ›{expected_shape}")
                        # å°è¯•è°ƒæ•´å½¢çŠ¶
                        if len(actual_shape) == 4 and len(expected_shape) == 4:
                            if actual_shape[1] != expected_shape[1]:
                                st.error(f"é€šé“æ•°ä¸åŒ¹é…: å®é™…{actual_shape[1]} vs æœŸæœ›{expected_shape[1]}")
                                # å¦‚æœæ˜¯é€šé“æ•°é—®é¢˜ï¼Œå°è¯•è½¬æ¢
                                if actual_shape[1] == 4 and expected_shape[1] == 3:
                                    input_data = input_data[:, :3, :, :]  # å–å‰3ä¸ªé€šé“
                                    st.info("å·²ä»4é€šé“è½¬æ¢ä¸º3é€šé“")
                    
                    # æ¨¡å‹æ¨ç†
                    outputs = model_session.run(None, {input_name: input_data})
                    
                    # æ˜¾ç¤ºè¾“å‡ºä¿¡æ¯
                    for i, output in enumerate(outputs):
                        st.info(f"è¾“å‡º {i} å½¢çŠ¶: {output.shape}")
                    
                    # åå¤„ç†
                    boxes, scores, class_ids = yolo_postprocess(
                        outputs, 
                        image_np.shape, 
                        conf_threshold=confidence_threshold
                    )
                    
                    # ç»˜åˆ¶ç»“æœ
                    result_image = draw_detections(
                        image_np, boxes, scores, class_ids, 
                        conf_threshold=confidence_threshold
                    )
                    
                    with col2:
                        st.subheader("ğŸ“Š æ£€æµ‹ç»“æœ")
                        st.image(result_image, use_column_width=True)
                        
                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        if boxes:
                            st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {len(boxes)} ä¸ªç¼ºé™·")
                            
                            # è¯¦ç»†ç»Ÿè®¡
                            with st.expander("ğŸ“ˆ æ£€æµ‹è¯¦æƒ…"):
                                defect_count = {}
                                for class_id in class_ids:
                                    class_name = CLASS_NAMES.get(class_id, f"ç±»åˆ«{class_id}")
                                    defect_count[class_name] = defect_count.get(class_name, 0) + 1
                                
                                for class_name, count in defect_count.items():
                                    st.write(f"**{class_name}**: {count} ä¸ª")
                        else:
                            st.info("â„¹ï¸ æœªæ£€æµ‹åˆ°æ˜æ˜¾ç¼ºé™·")
                            
                except Exception as e:
                    st.error(f"âŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())

else:
    st.info("ğŸ‘† è¯·ä¸Šä¼ ç”µç¼†å›¾ç‰‡å¼€å§‹æ£€æµ‹")
