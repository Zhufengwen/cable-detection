import streamlit as st
import numpy as np
from PIL import Image
import cv2
import onnxruntime as ort
import os

st.set_page_config(page_title="ç”µç¼†ç¼ºé™·æ£€æµ‹ç³»ç»Ÿ", layout="wide")
st.title("ğŸ”Œ ç”µç¼†ç¼ºé™·æ£€æµ‹ç³»ç»Ÿ")
st.markdown("ä¸Šä¼ ç”µç¼†å›¾ç‰‡ï¼ŒAIè‡ªåŠ¨æ£€æµ‹å„ç§ç¼ºé™·ç±»å‹")

@st.cache_resource
def load_onnx_model():
    """åŠ è½½ONNXæ¨¡å‹"""
    try:
        # æŸ¥æ‰¾å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶
        onnx_files = [f for f in os.listdir('.') if f.endswith('.onnx')]
        st.info(f"æ‰¾åˆ°çš„ONNXæ–‡ä»¶: {onnx_files}")
        
        if not onnx_files:
            st.error("âŒ æœªæ‰¾åˆ°ONNXæ¨¡å‹æ–‡ä»¶")
            return None
        
        model_path = onnx_files[0]
        st.info(f"å°è¯•åŠ è½½æ¨¡å‹: {model_path}")
        
        # è®¾ç½®ONNX Runtimeæä¾›è€…
        providers = ['CPUExecutionProvider']
        if ort.get_device() == 'GPU':
            providers.insert(0, 'CUDAExecutionProvider')
        
        session = ort.InferenceSession(model_path, providers=providers)
        
        # æ˜¾ç¤ºæ¨¡å‹è¾“å…¥ä¿¡æ¯
        model_inputs = session.get_inputs()
        st.success(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        for i, input_info in enumerate(model_inputs):
            st.info(f"è¾“å…¥ {i}: åç§°='{input_info.name}', å½¢çŠ¶={input_info.shape}, ç±»å‹={input_info.type}")
        
        return session
        
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None

def preprocess(image, target_size=640):
    """é¢„å¤„ç†å›¾åƒ - é€‚é…åŠ¨æ€è¾“å…¥å½¢çŠ¶"""
    # ç¡®ä¿å›¾åƒæ˜¯3é€šé“
    if len(image.shape) == 3 and image.shape[2] == 4:
        # å¦‚æœæ˜¯4é€šé“RGBAï¼Œè½¬æ¢ä¸º3é€šé“RGB
        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
    elif len(image.shape) == 2:
        # å¦‚æœæ˜¯ç°åº¦å›¾ï¼Œè½¬æ¢ä¸º3é€šé“
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    
    # è·å–åŸå§‹å°ºå¯¸
    original_h, original_w = image.shape[:2]
    
    # è®¡ç®—è°ƒæ•´åçš„å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”
    scale = min(target_size / original_w, target_size / original_h)
    new_w = int(original_w * scale)
    new_h = int(original_h * scale)
    
    # è°ƒæ•´å°ºå¯¸
    resized = cv2.resize(image, (new_w, new_h))
    
    # åˆ›å»ºå¡«å……åçš„å›¾åƒ (target_size x target_size)
    padded = np.full((target_size, target_size, 3), 114, dtype=np.uint8)
    padded[:new_h, :new_w] = resized
    
    # å½’ä¸€åŒ–
    img = padded.astype(np.float32) / 255.0
    
    # è½¬æ¢é€šé“é¡ºåº: HWC to CHW
    img = img.transpose(2, 0, 1)  # ä» [H, W, C] åˆ° [C, H, W]
    
    # æ·»åŠ æ‰¹æ¬¡ç»´åº¦: [C, H, W] åˆ° [1, C, H, W]
    img = np.expand_dims(img, 0)
    
    return img, (original_h, original_w), (new_h, new_w), scale

def yolo_postprocess(outputs, original_shape, padded_shape, scale, conf_threshold=0.25):
    """YOLOv8 ONNXè¾“å‡ºåå¤„ç†"""
    try:
        predictions = outputs[0]  # shape: [1, 84, 8400] æˆ–ç±»ä¼¼
        
        boxes = []
        scores = []
        class_ids = []
        
        # è§£æé¢„æµ‹ç»“æœ
        for i in range(predictions.shape[2]):
            prediction = predictions[0, :, i]
            
            # æå–è¾¹ç•Œæ¡† (x_center, y_center, width, height)
            x_center, y_center, width, height = prediction[0:4]
            
            # è½¬æ¢ä¸ºç»å¯¹åæ ‡ (åœ¨640x640å›¾åƒä¸Š)
            x1 = (x_center - width / 2) 
            y1 = (y_center - height / 2)
            x2 = (x_center + width / 2)
            y2 = (y_center + height / 2)
            
            # æå–ç±»åˆ«æ¦‚ç‡
            class_probs = prediction[4:]  # ä»ç¬¬4ä¸ªå¼€å§‹æ˜¯ç±»åˆ«æ¦‚ç‡
            class_id = np.argmax(class_probs)
            confidence = class_probs[class_id]
            
            if confidence > conf_threshold:
                # è°ƒæ•´åˆ°å¡«å……å‰çš„å°ºå¯¸
                pad_h, pad_w = padded_shape
                x1 = int(x1 * pad_w)
                y1 = int(y1 * pad_h)
                x2 = int(x2 * pad_w)
                y2 = int(y2 * pad_h)
                
                # è°ƒæ•´åˆ°åŸå§‹å›¾åƒå°ºå¯¸
                orig_h, orig_w = original_shape
                x1 = int(x1 / scale)
                y1 = int(y1 / scale)
                x2 = int(x2 / scale)
                y2 = int(y2 / scale)
                
                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, min(x1, orig_w))
                y1 = max(0, min(y1, orig_h))
                x2 = max(0, min(x2, orig_w))
                y2 = max(0, min(y2, orig_h))
                
                # åªæ·»åŠ æœ‰æ•ˆçš„è¾¹ç•Œæ¡†
                if x2 > x1 and y2 > y1 and (x2 - x1) > 5 and (y2 - y1) > 5:
                    boxes.append([x1, y1, x2, y2])
                    scores.append(float(confidence))
                    class_ids.append(int(class_id))
        
        return boxes, scores, class_ids
        
    except Exception as e:
        st.error(f"åå¤„ç†é”™è¯¯: {e}")
        return [], [], []

# æ›´ç®€å•çš„åå¤„ç†å‡½æ•°ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
def simple_yolo_postprocess(outputs, conf_threshold=0.25):
    """ç®€åŒ–çš„YOLOåå¤„ç†"""
    try:
        # å‡è®¾è¾“å‡ºæ˜¯ [1, 84, 8400] æ ¼å¼
        predictions = outputs[0]
        
        boxes = []
        scores = []
        class_ids = []
        
        # ç›´æ¥è§£æï¼Œä¸è¿›è¡Œå¤æ‚çš„åæ ‡è½¬æ¢
        for i in range(min(100, predictions.shape[2])):  # åªå¤„ç†å‰100ä¸ªé¢„æµ‹
            prediction = predictions[0, :, i]
            
            # æå–åæ ‡å’Œç±»åˆ«
            if len(prediction) >= 5:
                x_center, y_center, width, height = prediction[0:4]
                class_probs = prediction[4:]
                
                if len(class_probs) > 0:
                    class_id = np.argmax(class_probs)
                    confidence = class_probs[class_id]
                    
                    if confidence > conf_threshold:
                        # ç®€åŒ–çš„åæ ‡è®¡ç®—ï¼ˆç›¸å¯¹åæ ‡ï¼‰
                        x1 = int((x_center - width / 2) * 640)
                        y1 = int((y_center - height / 2) * 640)
                        x2 = int((x_center + width / 2) * 640)
                        y2 = int((y_center + height / 2) * 640)
                        
                        boxes.append([x1, y1, x2, y2])
                        scores.append(float(confidence))
                        class_ids.append(int(class_id))
        
        return boxes, scores, class_ids
        
    except Exception as e:
        st.error(f"ç®€åŒ–åå¤„ç†é”™è¯¯: {e}")
        return [], [], []

# ç±»åˆ«åç§°æ˜ å°„
CLASS_NAMES = {
    0: "æ–­è£‚è‚¡çº¿", 1: "ç„Šæ¥è‚¡çº¿", 2: "å¼¯æ›²è‚¡çº¿", 3: "é•¿åˆ’ç—•",
    4: "å‹ç¢", 5: "é—´éš”è‚¡çº¿", 6: "æ²‰ç§¯ç‰©", 7: "æ–­è£‚",
    8: "é›·å‡»æŸå"
}

def draw_detections(image, boxes, scores, class_ids, conf_threshold=0.25):
    """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    result = image.copy()
    
    # é¢œè‰²æ˜ å°„
    colors = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
        (255, 0, 255), (0, 255, 255), (255, 165, 0), (128, 0, 128),
        (165, 42, 42)
    ]
    
    detected_count = 0
    for i, (box, score, class_id) in enumerate(zip(boxes, scores, class_ids)):
        if score > conf_threshold:
            detected_count += 1
            x1, y1, x2, y2 = box
            
            # é€‰æ‹©é¢œè‰²
            color = colors[class_id % len(colors)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(result, (x1, y1), (x2, y2), color, 3)
            
            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
            class_name = CLASS_NAMES.get(class_id, f"ç±»åˆ«{class_id}")
            label = f"{class_name} {score:.2f}"
            
            # è®¡ç®—æ ‡ç­¾å°ºå¯¸
            (label_width, label_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
            )
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            label_bg_y1 = max(0, y1 - label_height - 10)
            label_bg_y2 = y1
            cv2.rectangle(result, 
                         (x1, label_bg_y1),
                         (x1 + label_width, label_bg_y2),
                         color, -1)
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
            text_y = max(15, y1 - 5)  # ç¡®ä¿æ–‡æœ¬ä¸ä¼šè¶…å‡ºå›¾åƒé¡¶éƒ¨
            cv2.putText(result, label, (x1, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    return result, detected_count

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ æ£€æµ‹è®¾ç½®")
    confidence_threshold = st.slider(
        "ç½®ä¿¡åº¦é˜ˆå€¼", 
        min_value=0.1, 
        max_value=0.9, 
        value=0.25,
        help="å€¼è¶Šå°æ£€æµ‹è¶Šæ•æ„Ÿï¼Œä½†å¯èƒ½äº§ç”Ÿæ›´å¤šè¯¯æ£€"
    )
    
    use_simple_postprocess = st.checkbox("ä½¿ç”¨ç®€åŒ–åå¤„ç†", value=True, 
                                       help="å¦‚æœæ£€æµ‹ä¸åˆ°ç›®æ ‡ï¼Œå°è¯•åˆ‡æ¢æ­¤é€‰é¡¹")
    
    st.markdown("---")
    st.markdown("### æ”¯æŒæ£€æµ‹çš„ç¼ºé™·ç±»å‹")
    for class_id, class_name in CLASS_NAMES.items():
        st.write(f"â€¢ {class_name}")

# ä¸»ç•Œé¢
st.markdown("---")

# åŠ è½½æ¨¡å‹
model_session = load_onnx_model()

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader(
    "ğŸ“¤ ä¸Šä¼ ç”µç¼†å›¾ç‰‡", 
    type=['jpg', 'jpeg', 'png'],
    help="æ”¯æŒ JPGã€JPEGã€PNG æ ¼å¼"
)

if uploaded_file is not None and model_session is not None:
    # è¯»å–å¹¶æ˜¾ç¤ºåŸå›¾
    image = Image.open(uploaded_file)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„æ—¶ç¡®ä¿å¤„ç†RGBAå›¾åƒ
    if image.mode == 'RGBA':
        image = image.convert('RGB')
    
    image_np = np.array(image)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“· åŸå›¾")
        st.image(image, use_column_width=True)
        st.write(f"å›¾åƒå°ºå¯¸: {image_np.shape[1]} x {image_np.shape[0]}")
    
    # æ£€æµ‹æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹æ£€æµ‹", type="primary", use_container_width=True):
        with st.spinner("ğŸ” AIæ­£åœ¨æ£€æµ‹ç”µç¼†ç¼ºé™·..."):
            try:
                # è·å–æ¨¡å‹è¾“å…¥ä¿¡æ¯
                input_name = model_session.get_inputs()[0].name
                
                # é¢„å¤„ç†
                input_data, original_shape, padded_shape, scale = preprocess(image_np)
                
                st.info(f"é¢„å¤„ç†ä¿¡æ¯:")
                st.info(f"- åŸå§‹å°ºå¯¸: {original_shape}")
                st.info(f"- å¡«å……åå°ºå¯¸: {padded_shape}") 
                st.info(f"- ç¼©æ”¾æ¯”ä¾‹: {scale:.3f}")
                st.info(f"- è¾“å…¥æ•°æ®å½¢çŠ¶: {input_data.shape}")
                
                # æ¨¡å‹æ¨ç†
                outputs = model_session.run(None, {input_name: input_data})
                
                # æ˜¾ç¤ºè¾“å‡ºä¿¡æ¯
                st.info("æ¨¡å‹è¾“å‡º:")
                for i, output in enumerate(outputs):
                    st.info(f"è¾“å‡º {i} å½¢çŠ¶: {output.shape}")
                
                # åå¤„ç†
                if use_simple_postprocess:
                    boxes, scores, class_ids = simple_yolo_postprocess(
                        outputs, conf_threshold=confidence_threshold
                    )
                    method = "ç®€åŒ–åå¤„ç†"
                else:
                    boxes, scores, class_ids = yolo_postprocess(
                        outputs, original_shape, padded_shape, scale, 
                        conf_threshold=confidence_threshold
                    )
                    method = "æ ‡å‡†åå¤„ç†"
                
                st.info(f"ä½¿ç”¨ {method}, æ£€æµ‹åˆ° {len(boxes)} ä¸ªå€™é€‰ç›®æ ‡")
                
                # ç»˜åˆ¶ç»“æœ
                result_image, detected_count = draw_detections(
                    image_np, boxes, scores, class_ids, 
                    conf_threshold=confidence_threshold
                )
                
                with col2:
                    st.subheader("ğŸ“Š æ£€æµ‹ç»“æœ")
                    st.image(result_image, use_column_width=True)
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    if detected_count > 0:
                        st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {detected_count} ä¸ªç¼ºé™·")
                        
                        # è¯¦ç»†ç»Ÿè®¡
                        with st.expander("ğŸ“ˆ æ£€æµ‹è¯¦æƒ…"):
                            defect_count = {}
                            for class_id in class_ids:
                                if scores[i] > confidence_threshold:
                                    class_name = CLASS_NAMES.get(class_id, f"ç±»åˆ«{class_id}")
                                    defect_count[class_name] = defect_count.get(class_name, 0) + 1
                            
                            for class_name, count in defect_count.items():
                                st.write(f"**{class_name}**: {count} ä¸ª")
                    else:
                        st.info("â„¹ï¸ æœªæ£€æµ‹åˆ°æ˜æ˜¾ç¼ºé™·")
                        st.info("""
                        å»ºè®®ï¼š
                        1. é™ä½ç½®ä¿¡åº¦é˜ˆå€¼
                        2. åˆ‡æ¢åå¤„ç†æ–¹æ³•
                        3. å°è¯•ä¸åŒçš„å›¾ç‰‡
                        """)
                        
            except Exception as e:
                st.error(f"âŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                import traceback
                with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                    st.code(traceback.format_exc())

elif model_session is None:
    st.warning("âš ï¸ ç­‰å¾…æ¨¡å‹åŠ è½½...")
else:
    st.info("ğŸ‘† è¯·ä¸Šä¼ ç”µç¼†å›¾ç‰‡å¼€å§‹æ£€æµ‹")

# é¡µè„š
st.markdown("---")
st.markdown("""
<style>
.footer {
    text-align: center;
    color: gray;
    font-size: 0.8em;
}
</style>
<div class="footer">
    ç”µç¼†ç¼ºé™·æ£€æµ‹ç³»ç»Ÿ | åŸºäºYOLOv8å’ŒONNX Runtime
</div>
""", unsafe_allow_html=True)
